{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T21:30:43.531171Z",
     "start_time": "2019-07-27T21:30:43.507355Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:27:01.946317Z",
     "start_time": "2019-07-25T21:27:01.941854Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the location of the Data\n",
    "path = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Feature Engineered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:28:24.690384Z",
     "start_time": "2019-07-25T21:27:46.825654Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{path}/interim/2017FeatEng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:31:15.195255Z",
     "start_time": "2019-07-25T21:31:14.995961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>Flight_Number_Reporting_Airline</th>\n",
       "      <th>Origin</th>\n",
       "      <th>OriginState</th>\n",
       "      <th>...</th>\n",
       "      <th>ARR_HOUR</th>\n",
       "      <th>DEP_HOUR</th>\n",
       "      <th>DOM_DIRECTION</th>\n",
       "      <th>flight_freq</th>\n",
       "      <th>LoadFactor</th>\n",
       "      <th>mf_name</th>\n",
       "      <th>mf_year</th>\n",
       "      <th>plane_model</th>\n",
       "      <th>eng_model</th>\n",
       "      <th>plane_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-05-06 00:00:00</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7824A</td>\n",
       "      <td>4652</td>\n",
       "      <td>SJC</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>East</td>\n",
       "      <td>17</td>\n",
       "      <td>0.745438</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>737-7BK</td>\n",
       "      <td>CFM56 SERIES</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-05-06 00:00:00</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8522P</td>\n",
       "      <td>4971</td>\n",
       "      <td>SJC</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>East</td>\n",
       "      <td>7</td>\n",
       "      <td>0.745438</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>737-800</td>\n",
       "      <td>CFM56-7B27E/F</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-05-06 00:00:00</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8617E</td>\n",
       "      <td>5113</td>\n",
       "      <td>SJC</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>East</td>\n",
       "      <td>8</td>\n",
       "      <td>0.745438</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>737-8H4</td>\n",
       "      <td>CFM56-7B27E</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-05-06 00:00:00</td>\n",
       "      <td>WN</td>\n",
       "      <td>N450WN</td>\n",
       "      <td>5150</td>\n",
       "      <td>SJC</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>East</td>\n",
       "      <td>3</td>\n",
       "      <td>0.745438</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>737-7H4</td>\n",
       "      <td>CFM56 SERIES</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-05-06 00:00:00</td>\n",
       "      <td>WN</td>\n",
       "      <td>N498WN</td>\n",
       "      <td>5711</td>\n",
       "      <td>SJC</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>East</td>\n",
       "      <td>10</td>\n",
       "      <td>0.745438</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>737-7H4</td>\n",
       "      <td>CFM56 SERIES</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter  Month  DayofMonth  DayOfWeek           FlightDate  \\\n",
       "0        2      5           6          6  2017-05-06 00:00:00   \n",
       "1        2      5           6          6  2017-05-06 00:00:00   \n",
       "2        2      5           6          6  2017-05-06 00:00:00   \n",
       "3        2      5           6          6  2017-05-06 00:00:00   \n",
       "4        2      5           6          6  2017-05-06 00:00:00   \n",
       "\n",
       "  Reporting_Airline Tail_Number  Flight_Number_Reporting_Airline Origin  \\\n",
       "0                WN      N7824A                             4652    SJC   \n",
       "1                WN      N8522P                             4971    SJC   \n",
       "2                WN      N8617E                             5113    SJC   \n",
       "3                WN      N450WN                             5150    SJC   \n",
       "4                WN      N498WN                             5711    SJC   \n",
       "\n",
       "  OriginState    ...     ARR_HOUR DEP_HOUR  DOM_DIRECTION  flight_freq  \\\n",
       "0          CA    ...            8        6           East           17   \n",
       "1          CA    ...           18       17           East            7   \n",
       "2          CA    ...           12       11           East            8   \n",
       "3          CA    ...           21       20           East            3   \n",
       "4          CA    ...           14       13           East           10   \n",
       "\n",
       "   LoadFactor  mf_name  mf_year  plane_model      eng_model  plane_age  \n",
       "0    0.745438   BOEING   2001.0      737-7BK   CFM56 SERIES       16.0  \n",
       "1    0.745438   BOEING   2017.0      737-800  CFM56-7B27E/F        0.0  \n",
       "2    0.745438   BOEING   2013.0      737-8H4    CFM56-7B27E        4.0  \n",
       "3    0.745438   BOEING   2004.0      737-7H4   CFM56 SERIES       13.0  \n",
       "4    0.745438   BOEING   2005.0      737-7H4   CFM56 SERIES       12.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:34:15.515806Z",
     "start_time": "2019-07-25T21:34:15.507108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5579279, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:34:06.927177Z",
     "start_time": "2019-07-25T21:33:59.755488Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a list with top 20 airport origins by flight volume\n",
    "top_20 = list(df.groupby('Origin').size().sort_values(ascending=False)[0:20].index)\n",
    "#create a list with top 5 airlines by flight volume\n",
    "top_5 = list(df.groupby('Reporting_Airline').size().sort_values(ascending=False)[0:5].index)\n",
    "#only use top 20 origin airports\n",
    "top_df = df[df.Origin.isin(top_20)]\n",
    "#only use top 5 airlines\n",
    "top_df = top_df[top_df.Reporting_Airline.isin(top_5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:34:19.945415Z",
     "start_time": "2019-07-25T21:34:19.940979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2458906, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:35:18.419252Z",
     "start_time": "2019-07-25T21:35:16.827810Z"
    }
   },
   "outputs": [],
   "source": [
    "#Add a column classifying if the flight is delayed or not using 15 minutes as delayed\n",
    "top_df['STATUS'] = top_df.ArrDelay.apply(lambda x: 1 if x >= 15 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:37:34.362672Z",
     "start_time": "2019-07-25T21:37:34.355552Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:39:59.534929Z",
     "start_time": "2019-07-25T21:39:57.321226Z"
    }
   },
   "outputs": [],
   "source": [
    "#Ensure the columns are strings\n",
    "top_df['mf_name'] = top_df['mf_name'].astype(str)\n",
    "top_df['mf_year'] = top_df['mf_year'].astype(str)\n",
    "top_df['plane_model'] = top_df['plane_model'].astype(str)\n",
    "top_df['eng_model'] = top_df['eng_model'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:43:05.567165Z",
     "start_time": "2019-07-25T21:43:01.682946Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "top_df['Reporting_Airline'] = le.fit_transform(top_df.Reporting_Airline.values)\n",
    "top_df['Tail_Number'] = le.fit_transform(top_df.Tail_Number.values)\n",
    "top_df['Origin'] = le.fit_transform(top_df.Origin.values)\n",
    "top_df['Dest'] = le.fit_transform(top_df.Dest.values)\n",
    "top_df['DOM_DIRECTION'] = le.fit_transform(top_df.DOM_DIRECTION.values)\n",
    "top_df['OriginState'] = le.fit_transform(top_df.OriginState.values)\n",
    "top_df['DestState'] = le.fit_transform(top_df.DestState.values)\n",
    "top_df['mf_name'] = le.fit_transform(top_df.mf_name.values)\n",
    "top_df['mf_year'] = le.fit_transform(top_df.mf_year.values)\n",
    "top_df['plane_model'] = le.fit_transform(top_df.plane_model.values)\n",
    "top_df['eng_model'] = le.fit_transform(top_df.eng_model.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:45:31.939576Z",
     "start_time": "2019-07-25T21:45:29.551613Z"
    }
   },
   "outputs": [],
   "source": [
    "top_df = top_df.drop(columns='FlightDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T21:45:42.535306Z",
     "start_time": "2019-07-25T21:45:42.490539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>Flight_Number_Reporting_Airline</th>\n",
       "      <th>Origin</th>\n",
       "      <th>OriginState</th>\n",
       "      <th>DestState</th>\n",
       "      <th>...</th>\n",
       "      <th>DEP_HOUR</th>\n",
       "      <th>DOM_DIRECTION</th>\n",
       "      <th>flight_freq</th>\n",
       "      <th>LoadFactor</th>\n",
       "      <th>mf_name</th>\n",
       "      <th>mf_year</th>\n",
       "      <th>plane_model</th>\n",
       "      <th>eng_model</th>\n",
       "      <th>plane_age</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1691</td>\n",
       "      <td>435</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340491</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>43</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1691</td>\n",
       "      <td>451</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.340491</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>43</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3116</td>\n",
       "      <td>4720</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>69</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3048</td>\n",
       "      <td>2435</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.833898</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2598</td>\n",
       "      <td>4757</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.795838</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>57</td>\n",
       "      <td>35</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Month  DayofMonth  DayOfWeek  Reporting_Airline  Tail_Number  \\\n",
       "25        2      5           6          6                  4         1691   \n",
       "26        2      5           6          6                  4         1691   \n",
       "27        2      5           6          6                  4         3116   \n",
       "28        2      5           6          6                  4         3048   \n",
       "29        2      5           6          6                  4         2598   \n",
       "\n",
       "    Flight_Number_Reporting_Airline  Origin  OriginState  DestState   ...    \\\n",
       "25                              435      19           15          4   ...     \n",
       "26                              451      19           15          4   ...     \n",
       "27                             4720      19           15         18   ...     \n",
       "28                             2435      19           15         42   ...     \n",
       "29                             4757      19           15          5   ...     \n",
       "\n",
       "    DEP_HOUR  DOM_DIRECTION  flight_freq  LoadFactor  mf_name  mf_year  \\\n",
       "25        18              2            1    0.340491       12       39   \n",
       "26         8              2           22    0.340491       12       39   \n",
       "27         9              0           23    0.805389       12       54   \n",
       "28        14              0            7    0.833898       12       52   \n",
       "29        13              0           15    0.795838       12       39   \n",
       "\n",
       "    plane_model  eng_model  plane_age  STATUS  \n",
       "25           48         43       16.0       0  \n",
       "26           48         43       16.0       0  \n",
       "27           69         57        1.0       0  \n",
       "28           69         56        3.0       0  \n",
       "29           57         35       16.0       0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T22:09:56.701477Z",
     "start_time": "2019-07-25T22:09:55.970367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay percentage: 0.1848797798695843\n"
     ]
    }
   ],
   "source": [
    "down = top_df[top_df.STATUS == 1]\n",
    "up = top_df[top_df.STATUS == 0]\n",
    "down = down.Reporting_Airline.count()\n",
    "up = up.Reporting_Airline.count()\n",
    "print(f'Delay percentage: {down/(up+down)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling the data to deal with Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T22:08:17.472624Z",
     "start_time": "2019-07-25T22:08:17.443361Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T22:10:12.398981Z",
     "start_time": "2019-07-25T22:10:11.064987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    454602\n",
       "0    454602\n",
       "Name: STATUS, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's first separate majority class and minority class and resample\n",
    "\n",
    "df_majority = top_df[top_df.STATUS == 0]\n",
    "df_minority = top_df[top_df.STATUS == 1]\n",
    "\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=down,     # to match minority class\n",
    "                                 random_state=42) # reproducible results\n",
    "# combine the new dataframes\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "df_downsampled.STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data into Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T22:10:28.750876Z",
     "start_time": "2019-07-25T22:10:28.737854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'Reporting_Airline',\n",
       "       'Tail_Number', 'Flight_Number_Reporting_Airline', 'Origin',\n",
       "       'OriginState', 'DestState', 'Dest', 'CRSElapsedTime', 'ArrDelay',\n",
       "       'Distance', 'DistanceGroup', 'tempF', 'wind', 'ave_vis', 'precip_sum',\n",
       "       'ARR_HOUR', 'DEP_HOUR', 'DOM_DIRECTION', 'flight_freq', 'LoadFactor',\n",
       "       'mf_name', 'mf_year', 'plane_model', 'eng_model', 'plane_age',\n",
       "       'STATUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T03:45:33.353871Z",
     "start_time": "2019-07-28T03:45:33.036651Z"
    }
   },
   "outputs": [],
   "source": [
    "df_downsampled['tempF'] = df_downsampled.tempF.apply(lambda x: (x - 32)*(5/9) + 273.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T03:39:56.912743Z",
     "start_time": "2019-07-28T03:39:56.608460Z"
    }
   },
   "outputs": [],
   "source": [
    "df_downsampled['plane_age'] = df_downsampled.plane_age.apply(lambda x: 0 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T03:46:10.697688Z",
     "start_time": "2019-07-28T03:46:10.477281Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df_downsampled.STATUS.values\n",
    "X = df_downsampled.drop(columns=['STATUS', 'ArrDelay']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T04:15:12.396164Z",
     "start_time": "2019-07-28T04:15:11.206300Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T22:12:55.830860Z",
     "start_time": "2019-07-25T22:12:55.824021Z"
    }
   },
   "outputs": [],
   "source": [
    "#clean up memory\n",
    "del df, top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (untuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:43:14.881756Z",
     "start_time": "2019-07-26T18:43:14.875367Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:43:33.873916Z",
     "start_time": "2019-07-26T18:43:33.868420Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:01:40.909014Z",
     "start_time": "2019-07-26T18:45:24.549228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: AdaBoost, accuracy: 0.6047810999719535, precision: 0.5916942475892525,          recall: 0.6809998463126001, confusion matrix: [[47939 42808]\n",
      " [29059 62035]]\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "precision = precision_score(y_test, y_pred_mlp)\n",
    "recall = recall_score(y_test, y_pred_mlp)\n",
    "cm = confusion_matrix(y_test, y_pred_mlp)\n",
    "# Evaluate clf's accuracy on the test set\n",
    "print(f'MLP: accuracy: {accuracy}, precision: {precision},\\\n",
    "          recall: {recall}, confusion matrix: {cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:25:50.204434Z",
     "start_time": "2019-07-26T19:25:50.128867Z"
    }
   },
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T04:06:55.139755Z",
     "start_time": "2019-07-26T19:25:55.146199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_iter=200,\n",
       "                                     momentum=0.9, n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_sta...\n",
       "                                     solver='adam', tol=0.0001,\n",
       "                                     validation_fraction=0.1, verbose=False,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'alpha': [0.0001, 0.05],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n",
       "                                                (100,)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf_mlp = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T04:07:13.213122Z",
     "start_time": "2019-07-27T04:07:13.034022Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.521 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.548 (+/-0.039) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.525 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.548 (+/-0.039) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.520 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.523 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.527 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.523 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.524 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.570 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.528 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.570 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.524 (+/-0.001) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.523 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.525 (+/-0.000) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.523 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.522 (+/-0.001) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.520 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.526 (+/-0.000) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.520 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.522 (+/-0.001) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.520 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.527 (+/-0.001) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.520 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.500 (+/-0.000) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.611 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.500 (+/-0.000) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.611 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.500 (+/-0.000) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.618 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.500 (+/-0.000) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.618 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.500 (+/-0.000) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.602 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.501 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.602 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.500 (+/-0.000) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.581 (+/-0.009) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.500 (+/-0.000) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.581 (+/-0.009) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.525 (+/-0.072) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.591 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.525 (+/-0.072) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.591 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.503 (+/-0.007) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.583 (+/-0.009) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.503 (+/-0.007) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.583 (+/-0.009) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf_mlp.best_params_)\n",
    "\n",
    "# All results\n",
    "means = clf_mlp.cv_results_['mean_test_score']\n",
    "stds = clf_mlp.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf_mlp.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T04:07:19.156861Z",
     "start_time": "2019-07-27T04:07:14.958224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61     90747\n",
      "           1       0.62      0.64      0.63     91094\n",
      "\n",
      "    accuracy                           0.62    181841\n",
      "   macro avg       0.62      0.62      0.62    181841\n",
      "weighted avg       0.62      0.62      0.62    181841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, clf_mlp.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T14:56:14.201183Z",
     "start_time": "2019-07-27T14:56:00.379865Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "params = {'learning_rate':0.01,\n",
    "          'objective' :'binary',\n",
    "          'num_leaves' : 100,\n",
    "          'feature_fraction': 0.75, \n",
    "          'bagging_fraction': 0.8, \n",
    "          'bagging_freq':1,\n",
    "          'boosting_type' : 'gbdt',\n",
    "          'metric': 'binary_logloss'}\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "lgbm = lgb.train(params, train_data, 100)\n",
    "\n",
    "y_pred_lgb = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T14:56:17.451630Z",
     "start_time": "2019-07-27T14:56:17.439255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49025986, 0.49985671, 0.48524547, ..., 0.495948  , 0.34475376,\n",
       "       0.47941924])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T14:56:18.650149Z",
     "start_time": "2019-07-27T14:56:18.627630Z"
    }
   },
   "outputs": [],
   "source": [
    "y_binary = np.where(y_pred_lgb < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T14:56:19.972832Z",
     "start_time": "2019-07-27T14:56:19.704304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66     90747\n",
      "           1       0.66      0.62      0.64     91094\n",
      "\n",
      "    accuracy                           0.65    181841\n",
      "   macro avg       0.65      0.65      0.65    181841\n",
      "weighted avg       0.65      0.65      0.65    181841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T04:47:36.290693Z",
     "start_time": "2019-07-27T04:47:35.993283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM: accuracy: 0.6498809399420373, precision: 0.6603526495486647,        recall: 0.6199749709091708, confusion matrix: [[61699 29048]\n",
      " [34618 56476]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_binary)\n",
    "precision = precision_score(y_test, y_binary)\n",
    "recall = recall_score(y_test, y_binary)\n",
    "cm = confusion_matrix(y_test, y_binary)\n",
    "# Evaluate clf's accuracy on the test set\n",
    "print(f'LightGBM: accuracy: {accuracy}, precision: {precision},\\\n",
    "        recall: {recall}, confusion matrix: {cm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Classifiers and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:05:36.688646Z",
     "start_time": "2019-07-27T19:05:36.670243Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:05:36.723016Z",
     "start_time": "2019-07-27T19:05:36.691760Z"
    }
   },
   "outputs": [],
   "source": [
    "#instantiate models\n",
    "seed = 42\n",
    "clf = RandomForestClassifier(random_state=seed)\n",
    "xgb = XGBClassifier(random_state=seed)\n",
    "ada = AdaBoostClassifier(random_state=seed)\n",
    "xtr = ExtraTreesClassifier(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:05:42.055996Z",
     "start_time": "2019-07-27T19:05:42.047764Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = [('Random Forest', clf), ('XGBoost', xgb), ('ExtraTrees', xtr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:05:43.543317Z",
     "start_time": "2019-07-27T19:05:43.537310Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,\\\n",
    "precision_score, recall_score, precision_recall_curve, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:08:54.043103Z",
     "start_time": "2019-07-27T19:05:47.390224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67     90747\n",
      "           1       0.67      0.57      0.62     91094\n",
      "\n",
      "    accuracy                           0.64    181841\n",
      "   macro avg       0.65      0.64      0.64    181841\n",
      "weighted avg       0.65      0.64      0.64    181841\n",
      "\n",
      "accuracy: 0.644420125274278\n",
      "precision: 0.6708415732805977\n",
      "recall: 0.5697521241794191\n",
      "confusion matrix: [[65281 25466]\n",
      " [39193 51901]]\n",
      "------------------------------\n",
      "name: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65     90747\n",
      "           1       0.65      0.62      0.64     91094\n",
      "\n",
      "    accuracy                           0.64    181841\n",
      "   macro avg       0.64      0.64      0.64    181841\n",
      "weighted avg       0.64      0.64      0.64    181841\n",
      "\n",
      "accuracy: 0.6436392232774787\n",
      "precision: 0.6502714751100188\n",
      "recall: 0.6245087492041188\n",
      "confusion matrix: [[60151 30596]\n",
      " [34205 56889]]\n",
      "------------------------------\n",
      "name: ExtraTrees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66     90747\n",
      "           1       0.67      0.57      0.62     91094\n",
      "\n",
      "    accuracy                           0.64    181841\n",
      "   macro avg       0.65      0.64      0.64    181841\n",
      "weighted avg       0.65      0.64      0.64    181841\n",
      "\n",
      "accuracy: 0.642462370972443\n",
      "precision: 0.6659497295577473\n",
      "recall: 0.5744286122027795\n",
      "confusion matrix: [[64499 26248]\n",
      " [38767 52327]]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf_algo in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf_algo.fit(X_train, y_train)    \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf_algo.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print(f'name: {clf_name}')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # Evaluate clf's accuracy on the test set \n",
    "    print(f'accuracy: {accuracy}')\n",
    "    print(f'precision: {precision}')\n",
    "    print(f'recall: {recall}')\n",
    "    print(f'confusion matrix: {cm}')\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:13:17.712932Z",
     "start_time": "2019-07-27T19:10:11.586748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68     90747\n",
      "           1       0.69      0.60      0.64     91094\n",
      "\n",
      "    accuracy                           0.66    181841\n",
      "   macro avg       0.66      0.66      0.66    181841\n",
      "weighted avg       0.66      0.66      0.66    181841\n",
      "\n",
      "accuracy: 0.6621718974268729\n",
      "precision: 0.6864354581222581\n",
      "recall: 0.5994686807034492\n",
      "confusion matrix: [[65802 24945]\n",
      " [36486 54608]]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import VotingClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Evaluate clf's accuracy on the test set\n",
    "print(f'name: Voting Classifier')\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Evaluate clf's accuracy on the test set \n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'confusion matrix: {cm}')\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T03:30:04.690323Z",
     "start_time": "2019-07-26T03:30:04.684330Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:37:47.615183Z",
     "start_time": "2019-07-27T19:37:47.572339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of trees for tree ensambles\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 150, num = 2)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(50, 105, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [6, 8, 12]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T14:15:36.237191Z",
     "start_time": "2019-07-26T14:15:36.174914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [50, 63, 77, 91, 105, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [6, 8, 12],\n",
      " 'min_samples_split': [5, 10, 20],\n",
      " 'n_estimators': [70, 85, 100]}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T15:25:28.534980Z",
     "start_time": "2019-07-26T14:15:38.967968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 64.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_sc...\n",
       "                                                    random_state=42, verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='warn', n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [50, 63, 77, 91, 105,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [6, 8, 12],\n",
       "                                        'min_samples_split': [5, 10, 20],\n",
       "                                        'n_estimators': [70, 85, 100]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 20, \\\n",
    "                               cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T15:25:35.785526Z",
     "start_time": "2019-07-26T15:25:35.770763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 8,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T21:31:09.998799Z",
     "start_time": "2019-07-27T21:31:09.982167Z"
    }
   },
   "outputs": [],
   "source": [
    "#define and store ExtraTreeClassifier best parameters\n",
    "rf_params = rf_random.best_params_\n",
    "with open('rf_params', 'wb') as f:\n",
    "    pickle.dump(rf_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T15:57:11.765978Z",
     "start_time": "2019-07-26T15:25:37.063638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed: 28.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_state=42, reg_alpha=0,\n",
       "                                           reg_lambda=1, scal...\n",
       "                   iid='warn', n_iter=10, n_jobs=4,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.5],\n",
       "                                        'learning_rate': [0.01, 0.1],\n",
       "                                        'max_depth': [5, 10],\n",
       "                                        'min_child_weight': [2, 6],\n",
       "                                        'n_estimators': [50, 100],\n",
       "                                        'nthread': [4],\n",
       "                                        'objective': ['reg:linear'],\n",
       "                                        'silent': [1],\n",
       "                                        'subsample': [0.7, 0.9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              #'objective':['reg:linear'],\n",
    "              'learning_rate': [0.01, 0.1],\n",
    "              'max_depth': [6, 12], \n",
    "              'min_child_weight': [2, 6],\n",
    "              #'verbosity': [1],\n",
    "              'subsample': [1.0],\n",
    "              'colsample_bytree': [0.3, 0.5],\n",
    "              'gamma': [0],\n",
    "              'n_estimators': [100, 150]}\n",
    "\n",
    "xgb_rand = RandomizedSearchCV(xgb,\n",
    "                              parameters,\n",
    "                              cv = 3,\n",
    "                              n_jobs = 4,\n",
    "                              verbose=True)\n",
    "\n",
    "xgb_rand.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T15:57:20.695958Z",
     "start_time": "2019-07-26T15:57:20.636097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.7,\n",
       " 'silent': 1,\n",
       " 'objective': 'reg:linear',\n",
       " 'nthread': 4,\n",
       " 'n_estimators': 100,\n",
       " 'min_child_weight': 6,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.1,\n",
       " 'colsample_bytree': 0.3}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_rand.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T21:31:05.044417Z",
     "start_time": "2019-07-27T21:31:05.038393Z"
    }
   },
   "outputs": [],
   "source": [
    "#define and store ExtraTreeClassifier best parameters\n",
    "xgb_params = xgb_rand.best_params_\n",
    "with open('xgb_params', 'wb') as f:\n",
    "    pickle.dump(xgb_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:35:53.777029Z",
     "start_time": "2019-07-27T19:35:53.769898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False)>\n"
     ]
    }
   ],
   "source": [
    "pprint(xtr.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:39:06.552308Z",
     "start_time": "2019-07-27T19:39:06.547027Z"
    }
   },
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T21:29:00.288445Z",
     "start_time": "2019-07-27T19:39:22.922657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 107.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 85,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 6,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 77,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr_tune = RandomizedSearchCV(estimator = xtr, param_distributions = param_dist, n_iter = 50, \\\n",
    "                               cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "xtr_tune.fit(X_train, y_train)\n",
    "xtr_tune.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T21:30:51.261891Z",
     "start_time": "2019-07-27T21:30:51.254831Z"
    }
   },
   "outputs": [],
   "source": [
    "#define and store ExtraTreeClassifier best parameters\n",
    "xtr_params = xtr_tune.best_params_\n",
    "with open('xtr_params', 'wb') as f:\n",
    "    pickle.dump(xtr_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Random Forest best parameters\n",
    "with open('rf_params', 'rb') as f:\n",
    "    rf_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import XGBoost best parameters\n",
    "with open('xgb_params', 'rb') as f:\n",
    "    xgb_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ExtraTreeClassifier best parameters\n",
    "with open('xtr_params', 'rb') as f:\n",
    "    xtr_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T21:33:51.646173Z",
     "start_time": "2019-07-27T21:33:51.592590Z"
    }
   },
   "outputs": [],
   "source": [
    "#instantiate models\n",
    "seed = 42\n",
    "new_clf = RandomForestClassifier(**rf_random.best_params_, random_state=seed)\n",
    "new_xgb = XGBClassifier(**xgb_rand.best_params_, random_state=seed)\n",
    "new_xtr = ExtraTreesClassifier(**xtr_tune.best_params_, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T21:33:53.472891Z",
     "start_time": "2019-07-27T21:33:53.460658Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = [('Random Forest', new_clf), ('XGBoost', new_xgb), ('ExtraTrees', new_xtr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T21:44:58.564232Z",
     "start_time": "2019-07-27T21:33:55.855084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69     90747\n",
      "           1       0.70      0.66      0.68     91094\n",
      "\n",
      "    accuracy                           0.69    181841\n",
      "   macro avg       0.69      0.69      0.69    181841\n",
      "weighted avg       0.69      0.69      0.69    181841\n",
      "\n",
      "accuracy: 0.6856154552603648\n",
      "precision: 0.6950487535645294\n",
      "recall: 0.6635673041034535\n",
      "confusion matrix: [[64226 26521]\n",
      " [30647 60447]]\n",
      "name: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.70     90747\n",
      "           1       0.70      0.67      0.68     91094\n",
      "\n",
      "    accuracy                           0.69    181841\n",
      "   macro avg       0.69      0.69      0.69    181841\n",
      "weighted avg       0.69      0.69      0.69    181841\n",
      "\n",
      "accuracy: 0.6894264769771393\n",
      "precision: 0.6983737694397011\n",
      "recall: 0.6689573407688761\n",
      "confusion matrix: [[64428 26319]\n",
      " [30156 60938]]\n",
      "name: ExtraTrees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69     90747\n",
      "           1       0.69      0.67      0.68     91094\n",
      "\n",
      "    accuracy                           0.68    181841\n",
      "   macro avg       0.68      0.68      0.68    181841\n",
      "weighted avg       0.68      0.68      0.68    181841\n",
      "\n",
      "accuracy: 0.6824258555551278\n",
      "precision: 0.6895865550805058\n",
      "recall: 0.6657408830438887\n",
      "confusion matrix: [[63448 27299]\n",
      " [30449 60645]]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf_algo in classifiers:    \n",
    "\n",
    "    # Fit clf to the training set\n",
    "    clf_algo.fit(X_train, y_train)    \n",
    "    \n",
    "    # Predict y_pred\n",
    "    y_pred = clf_algo.predict(X_test)\n",
    "          \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'name: {clf_name}')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # Evaluate clf's accuracy on the test set \n",
    "    print(f'accuracy: {accuracy}')\n",
    "    print(f'precision: {precision}')\n",
    "    print(f'recall: {recall}')\n",
    "    print(f'confusion matrix: {cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T21:56:04.577422Z",
     "start_time": "2019-07-27T21:45:02.422673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69     90747\n",
      "           1       0.70      0.67      0.68     91094\n",
      "\n",
      "    accuracy                           0.69    181841\n",
      "   macro avg       0.69      0.69      0.69    181841\n",
      "weighted avg       0.69      0.69      0.69    181841\n",
      "\n",
      "accuracy: 0.6892120038935113\n",
      "precision: 0.6978623088894992\n",
      "recall: 0.6694403583111951\n",
      "confusion matrix: [[64345 26402]\n",
      " [30112 60982]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f'Voting Classifier: ')\n",
    "print(classification_report(y_test, y_pred))\n",
    "    # Evaluate clf's accuracy on the test set \n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'confusion matrix: {cm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Random Forest\n",
    " - accuracy: 0.6444\n",
    " - precision: 0.6708\n",
    " - recall: 0.5697\n",
    " - confusion matrix: [[65281 25466]\n",
    " [39193 51901]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:08:00.129351Z",
     "start_time": "2019-07-26T18:08:00.114219Z"
    }
   },
   "source": [
    " \n",
    " |' | Predicted On-time | Predicted Delayed |\n",
    " |-- | --- | --- |\n",
    " |Actual On-time |65281|25466|\n",
    " |Actual Delayed |39193|51901|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - XGBoost: \n",
    " - accuracy: 0.6436\n",
    " - precision: 0.6502\n",
    " - recall: 0.6245\n",
    " - confusion matrix: [[60151 30596]\n",
    " [34205 56889]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " |' | Predicted On-time | Predicted Delayed |\n",
    " |-- | --- | --- |\n",
    " |Actual On-time |60151|30596|\n",
    " |Actual Delayed |34205|56889|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Extremely Randomized Trees: \n",
    " - accuracy: 0.6424\n",
    " - precision: 0.6659\n",
    " - recall: 0.5744\n",
    " - confusion matrix: [[64499 26248]\n",
    " [38767 52327]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " |' | Predicted On-time | Predicted Delayed |\n",
    " |-- | --- | --- |\n",
    " |Actual On-time |64499|26248|\n",
    " |Actual Delayed |38767|52327|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Random Forest, \n",
    " - accuracy: 0.6856\n",
    " - precision: 0.6950\n",
    " - recall: 0.6635\n",
    " - confusion matrix: [[64226 26521]\n",
    " [30647 60447]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " |' | Predicted On-time | Predicted Delayed |\n",
    " |-- | --- | --- |\n",
    " |Actual On-time |64226|26521|\n",
    " |Actual Delayed |30647|60447|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - XGBoost, \n",
    " - accuracy: 0.6894\n",
    " - precision: 0.6983\n",
    " - recall: 0.6689\n",
    " - confusion matrix: [[64428 26319]\n",
    " [30156 60938]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " |' | Predicted On-time | Predicted Delayed |\n",
    " |-- | --- | --- |\n",
    " |Actual On-time |64428|26319|\n",
    " |Actual Delayed |30156|60938|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Extremely Randomized Trees\n",
    " - accuracy: 0.6824\n",
    " - precision: 0.6895\n",
    " - recall: 0.6657\n",
    " - confusion matrix: [[63448 27299]\n",
    " [30449 60645]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " |' | Predicted On-time | Predicted Delayed |\n",
    " |-- | --- | --- |\n",
    " |Actual On-time |63448|27299|\n",
    " |Actual Delayed |30449|60645|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Voting Classifier:\n",
    " - accuracy: 0.6892\n",
    " - precision: 0.6978\n",
    " - recall: 0.6694\n",
    " - confusion matrix: [[64345 26402]\n",
    " [30112 60982]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " |' | Predicted On-time | Predicted Delayed |\n",
    " |-- | --- | --- |\n",
    " |Actual On-time |64345|26402|\n",
    " |Actual Delayed |30112|60982|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "679px",
    "left": "1587px",
    "right": "20px",
    "top": "120px",
    "width": "313px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
